{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker\n",
    "\n",
    "![docker-logo](media/docker-logo.png)\n",
    "\n",
    "Since it's launch in March 20, 2013, docker has reshaped alot of companies' ideas about development and production. Docker enabled developers to isolate and have reproducable application results across **any** environment where the application is or would be running, given, that an environment has docker engine installed. A developer can simulate any production environment on his/hers computer. This environment isolation and seamless transition between development and production saves alot of time and headaches.    \n",
    "\n",
    "## What is docker?  \n",
    "\n",
    "Docker is an **ecosystem of managing containers**. The definition splits into terms with definitions of their own:\n",
    "\n",
    "* A **docker ecosystem** is a collection of *docker backend engine*, *docker image registry* and any other helper software for container and image managment.  \n",
    "\n",
    "* A **docker container** is a runtime instance of a docker image. An informal definition of a container is that it is an isolated application with all the needed dependencies.\n",
    "\n",
    "* **Runtime** is a phase of a program when the instructions (code) are beeing actively run on a CPU. While the program is running (is in *runtime*), it is assigned a PID.  \n",
    "\n",
    "* An **instance** is an object that is created using a template (in docker universe - an image).\n",
    "\n",
    "* A docker **image** is an ordered collection of root filesystem changes and the corresponding execution parameters for use within a container runtime.\n",
    "\n",
    "* A **docker backend engine** is the main program that creates images, containers and manages every other process that is docker related. Nothing will run if docker backend is not installed on a system.  \n",
    "\n",
    "* A **docker image registry** is an application that enables the storing, updating and downloading of docker images. The most popular image registry is **https://hub.docker.com/**. This book's image can be publicly accesed via https://hub.docker.com/repository/docker/eligijusbujokas/ml-serving-book\n",
    "\n",
    "A high level graph of docker engine on a machine running it: \n",
    "\n",
    "![docker-overview](media/docker-overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the bottom of the graph there is OS hardware components: RAM, CPU and space to store files, among other things. Docker interacts with the resources of the computer via the OS kernel. Therefore, there may be some glitches and bugs when working on docker in Linux vs on Windows, altough **most** of the time, the containers on both OS work the same. \n",
    "\n",
    "Every docker image has it's own space in the filesystem. \n",
    "\n",
    "Every running docker container has an isolated RAM, CPU, disk space and GPU resources that only it can reach. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing docker on Ubuntu\n",
    "\n",
    "First, update the packages in the host machine:\n",
    "\n",
    "```\n",
    "sudo apt update\n",
    "``` \n",
    "\n",
    "Next, install some prerequisites for apt package installation via HTTPS:\n",
    "\n",
    "```\n",
    "sudo apt install apt-transport-https ca-certificates curl software-properties-common\n",
    "```\n",
    "\n",
    "Then add the GPG key for the official Docker repository:\n",
    "\n",
    "```\n",
    "curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\n",
    "```\n",
    "\n",
    "Add the Docker repository to apt (Ubuntu package manager) sources:\n",
    "\n",
    "```\n",
    "sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu focal stable\"\n",
    "``` \n",
    "\n",
    "Docker engine installation:\n",
    "\n",
    "```\n",
    "sudo apt install docker-ce\n",
    "```\n",
    "\n",
    "Docker should now be installed, the daemon started, and the process enabled to start on boot. To check whether everything is OK use the command: \n",
    "\n",
    "```\n",
    "docker run hello-world\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker images \n",
    "\n",
    "Docker images are like recipes and docker containers are the cakes made out of those recipes. There can be alot of cakes, but only one recipe. \n",
    "\n",
    "![docker-image-containers](media/image-containers.png)\n",
    "\n",
    "Lets say we want to build an image that runs a container that calculates the most popular bigrams (two words separated by whitespace) from the Netflix movie descriptions.\n",
    "\n",
    "Docker images are built with commands in **Dockerfiles**. An example dockerfile: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# The base image from where we are building the container;\n",
      "# All the official images can be found in DockerHub\n",
      "FROM ubuntu:20.04\n",
      "\n",
      "# Intalling all the packages that will be necessary for the container\n",
      "# For now, we are only installing python3, pip and c++ compiler for the ubuntu system\n",
      "RUN apt update && apt install -y \\\n",
      "    python3-pip \\\n",
      "    gcc \n",
      "\n",
      "# We can make and set a working directory in the container \n",
      "WORKDIR /ramen-app \n",
      "\n",
      "# Copying all the files needed from the local computer to the container \n",
      "COPY netflix_titles.csv . \n",
      "COPY get_top_bigrams.py . \n",
      "COPY requirements.txt . \n",
      "\n",
      "# Installing all the python packages needed for the analysis \n",
      "RUN pip install -r requirements.txt\n",
      "\n",
      "# Running the python script that will generate the top bigrams\n",
      "CMD [\"python\", \"get_top_bigrams.py\"]"
     ]
    }
   ],
   "source": [
    "!cat docker-example/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build the image and store it in the local filesystem, use the command: \n",
    "\n",
    "```\n",
    "docker build -t <image name> -f <path to Dockerfile directory>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1/8 : FROM ubuntu:20.04\n",
      " ---> c29284518f49\n",
      "Step 2/8 : RUN apt update && apt install -y     python3-pip     gcc\n",
      " ---> Using cache\n",
      " ---> b817f6a3a0de\n",
      "Step 3/8 : WORKDIR /ramen-app\n",
      " ---> Using cache\n",
      " ---> 69139c295440\n",
      "Step 4/8 : COPY netflix_titles.csv .\n",
      " ---> Using cache\n",
      " ---> 4beeebe50e91\n",
      "Step 5/8 : COPY get_top_bigrams.py .\n",
      " ---> 55abd39b7c03\n",
      "Step 6/8 : COPY requirements.txt .\n",
      " ---> b0693d95cb35\n",
      "Step 7/8 : RUN pip install -r requirements.txt\n",
      " ---> Running in e13bec70a5de\n",
      "Collecting pandas==1.3.0\n",
      "  Downloading pandas-1.3.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (10.6 MB)\n",
      "Collecting numpy==1.21.4\n",
      "  Downloading numpy-1.21.4-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "Collecting scikit-learn==1.0.1\n",
      "  Downloading scikit_learn-1.0.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.9 MB)\n",
      "Collecting pytz>=2017.3\n",
      "  Downloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
      "Collecting python-dateutil>=2.7.3\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting scipy>=1.1.0\n",
      "  Downloading scipy-1.7.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.3 MB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
      "Collecting six>=1.5\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: numpy, pytz, six, python-dateutil, pandas, scipy, joblib, threadpoolctl, scikit-learn\n",
      "Successfully installed joblib-1.1.0 numpy-1.21.4 pandas-1.3.0 python-dateutil-2.8.2 pytz-2021.3 scikit-learn-1.0.1 scipy-1.7.2 six-1.16.0 threadpoolctl-3.0.0\n",
      "Removing intermediate container e13bec70a5de\n",
      " ---> 7620c4c69a1d\n",
      "Step 8/8 : CMD [\"python3\", \"get_top_bigrams.py\"]\n",
      " ---> Running in 1ea38394e922\n",
      "Removing intermediate container 1ea38394e922\n",
      " ---> 01220243d5b0\n",
      "Successfully built 01220243d5b0\n",
      "Successfully tagged netflix-bigrams:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build -t netflix-bigrams docker-example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first building of the image takes a long time, because everything needs to be downloaded fresh. Additional builds will be faster, because some of the information is cached.\n",
    "\n",
    "After the image is built, it is stored in (Ubuntu) */var/lib/docker/image* directory. When we \"build\" and image, docker engine creates entries and new files in the image directory and prepares to create a container in runtime using the gathered information in build time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker containers \n",
    "\n",
    "Docker can only run containers with built images. To run a container with an image which has a known tag (in our case - **netflix-bigrams**), we can use the command:\n",
    "\n",
    "```\n",
    "docker run <image name>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 term  count\n",
      "841  this documentary    234\n",
      "926           when he    173\n",
      "395       high school    145\n",
      "755          stand up    145\n",
      "986          year old    145\n",
      "276           for his    115\n",
      "928          when his    113\n",
      "998       young woman    111\n",
      "995         young man    110\n",
      "420        his family    105\n",
      "460          his wife    103\n",
      "439          his life    102\n",
      "274           for her    102\n",
      "446           his own    100\n",
      "615          new york     98\n",
      "934          when she     98\n",
      "722          sets out     94\n",
      "805       their lives     94\n",
      "308          from his     89\n",
      "209        each other     89\n"
     ]
    }
   ],
   "source": [
    "!docker run netflix-bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The container outputed the top bigrams used in netflix movie descriptions. \n",
    "\n",
    "After the container has done it's task, it is shutdown, all the data that was generated in the container is deleted and every bit of resource that the container was using is freed up for all other PIDs in the host machine.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharing docker images \n",
    "\n",
    "To run a container from an image in another computer or the cloud, the first thing to remember is that the host machine which will run the container has to have docker backend engine installed. \n",
    "\n",
    "To share the images, there are multiple options: \n",
    "\n",
    "### DockerHub account \n",
    "\n",
    "Any user of docker can open a free or a business account in DockerHub via **https://hub.docker.com/**. After signing up, a user can push and pull images directly to and from the cloud. \n",
    "\n",
    "```\n",
    "docker push <docker hub username>/<image name>\n",
    "```\n",
    "\n",
    "Then, if the image is public, any person can download the image using the command:\n",
    "\n",
    "```\n",
    "docker pull <docker hub username>/<image name>\n",
    "```\n",
    "\n",
    "For example, this book has an image in DockerHub and can be pulled using the command:\n",
    "\n",
    "```\n",
    "docker pull eligijusbujokas/ml-serving-book\n",
    "```\n",
    "\n",
    "### Saving an image to an archive\n",
    "\n",
    "To save an image into a sharable archive, use the command: \n",
    "\n",
    "```\n",
    "docker save -o <name of archive>.tar.gz <image name>\n",
    "```\n",
    "\n",
    "This will create a .tar.gz file which can be ingested by docker in any machine with the command \n",
    "\n",
    "```\n",
    "docker load --input <name of archive>.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "702d029752c7c667e866081f4be82ec9765259a2e8484bced05e549319c2e426"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('api_book': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
