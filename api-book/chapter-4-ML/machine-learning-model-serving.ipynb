{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic ML serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous chapter we have created two very important objects and stored them in files: \n",
    "\n",
    "**ml-model-xgb.pkl** - the fitted on data and ready to be used xgboost machine learning model. \n",
    "\n",
    "**ml-model-lr.pkl** - the fitted on data and ready to be used logistic regression machine learning model. \n",
    "\n",
    "**ml-features.json** - a dictionary containing the features that the model was trained with. **NOTE**: it is very important to preserve the exact **key** sequence in all the future use of the model. \n",
    "\n",
    "The file structure is as follows: \n",
    "\n",
    "```\n",
    "├── ml_models\n",
    "│   ├── ml-features.json\n",
    "│   ├── ml-model-lr.pkl\n",
    "│   └── ml-model-xgb.pkl\n",
    "```\n",
    "\n",
    "No matter what type of serving - simple or complex - we are doing, these two objects is a minimum requirement if we want anyone to use our ML solution.  \n",
    "\n",
    "A basic chart for ML model serving is the following: \n",
    "\n",
    "![ml-serving-basic](media/basic-ml-serving.png)\n",
    "\n",
    "The steps are the following: \n",
    "\n",
    "* Preparate the raw data for the model \n",
    "* Use the model with the prepared data\n",
    "* Store/use the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Json reading \n",
    "import json \n",
    "\n",
    "# Pickle reading \n",
    "import pickle\n",
    "\n",
    "# Operating system functionality \n",
    "import os \n",
    "\n",
    "# Input simulation \n",
    "from ipywidgets import interactive, widgets, interact\n",
    "from IPython.display import display\n",
    "\n",
    "# Data wrangling \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the model objects "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before any serving can be done, the necessary objects need to be loaded into the host computer memory. This simple fact is true even for the most complex real time ML model serving systems: somewhere, between all the clouds and servers, all the objects are loaded to computer memory and is used in runtime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bomb_planted': 'int64', 'ct_health_share': 'float64', 'ct_players_alive': 'float64', 't_players_alive': 'float64', 'ct_defuse_kit_present': 'int64', 'ct_helmets': 'float64', 't_helmets': 'float64'}\n"
     ]
    }
   ],
   "source": [
    "# Saving the path to the ML folder \n",
    "_ml_folder = os.path.join(\"..\", 'ml_models')\n",
    "_ml_model_path = os.path.join(_ml_folder, \"ml-model-lr.pkl\")\n",
    "_ml_features_path = os.path.join(_ml_folder, \"ml-features.json\")\n",
    "\n",
    "# Reading the model object \n",
    "model = pickle.load(open(_ml_model_path, 'rb'))\n",
    "features = json.load(open(_ml_features_path, 'rb'))\n",
    "\n",
    "# Printing out the features \n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model serving "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating input "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test out our ML model, we will simulate an input for it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has the bomb been planted? \n",
    "bomb_planted = True \n",
    "\n",
    "# Boolean for the presence of the difusal kit\n",
    "ct_defuse_kit_present = False\n",
    "\n",
    "# CT health share of total; the range is (0, 1.0)\n",
    "ct_health_share = 0.75\n",
    "\n",
    "# CT and T alive players; the value set is {1, 2, 3, 4, 5}\n",
    "ct_players_alive = 4\n",
    "t_players_alive = 3\n",
    "\n",
    "# CT and T helmets; the value set is {1, 2, 3, 4, 5}\n",
    "ct_helmets = 4\n",
    "t_helmets = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bomb_planted': True, 'ct_defuse_kit_present': False, 'ct_health_share': 0.75, 'ct_players_alive': 4, 't_players_alive': 3, 'ct_helmets': 4, 't_helmets': 3}\n"
     ]
    }
   ],
   "source": [
    "# Creating a dataframe which will be used as raw input \n",
    "raw_input = {\n",
    "    \"bomb_planted\": bomb_planted,\n",
    "    \"ct_defuse_kit_present\": ct_defuse_kit_present,\n",
    "    \"ct_health_share\": ct_health_share, \n",
    "    \"ct_players_alive\": ct_players_alive,\n",
    "    \"t_players_alive\": t_players_alive,\n",
    "    \"ct_helmets\": ct_helmets,\n",
    "    \"t_helmets\": t_helmets\n",
    "}\n",
    "\n",
    "# Displaying the raw input \n",
    "print(raw_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input preprocesing function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define a function that prepares the input for the model given the raw input dictionary and the saved features JSON object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(raw_input_dict: dict, features: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function that accepts the raw input dictionary and the features dictionary and returns a pandas dataframe with the input prepared for the model.\n",
    "    \"\"\"\n",
    "    # Extracting the key names \n",
    "    feature_names = list(raw_input_dict.keys())\n",
    "    original_feature_names = list(features.keys())\n",
    "\n",
    "    # Ensuring that all the keys present in **features** are in **raw_input_dict**\n",
    "    missing_features = set(original_feature_names) - set(feature_names)\n",
    "    if len(missing_features): \n",
    "        return print(f\"Missing features in input: {missing_features}\")\n",
    "\n",
    "    # Iterating and preprocesing \n",
    "    prepared_features = {}\n",
    "    for feature in feature_names:\n",
    "        # Extracting the type of the feature \n",
    "        feature_type = features.get(feature) \n",
    "\n",
    "        # Converting to that type \n",
    "        feature_value = raw_input_dict.get(feature)\n",
    "        \n",
    "        if feature_type == \"float64\":\n",
    "            feature_value = float(feature_value) \n",
    "        \n",
    "        if feature_type == \"int64\":\n",
    "            feature_value = int(feature_value)\n",
    "\n",
    "        # Saving to the prepared features dictionary\n",
    "        prepared_features[feature] = feature_value \n",
    "    \n",
    "    # Creating a dataframe from the prepared features \n",
    "    df = pd.DataFrame(prepared_features, index=[0])\n",
    "\n",
    "    # Ensuring that the names are in the exact order \n",
    "    df = df[original_feature_names]\n",
    "\n",
    "    # Returning the dataframe \n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocesed input for ML model:\n",
      "   bomb_planted  ct_health_share  ct_players_alive  t_players_alive  \\\n",
      "0             1             0.75               4.0              3.0   \n",
      "\n",
      "   ct_defuse_kit_present  ct_helmets  t_helmets  \n",
      "0                      0         4.0        3.0  \n"
     ]
    }
   ],
   "source": [
    "# Testing out the function \n",
    "input_df = prepare_input(raw_input, features)\n",
    "print(f\"Preprocesed input for ML model:\\n{input_df}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the input with the exact same structure with which the model was built, we can use that input for extracting predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34404195 0.65595805]\n"
     ]
    }
   ],
   "source": [
    "# Getting the probabilities \n",
    "p = model.predict_proba(input_df)[0]\n",
    "\n",
    "# Initial results \n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extracted probabilities is vector of two and defines the following probabilities: \n",
    "\n",
    "$$ \\mathbb{P(Y = 0|X)} $$\n",
    "\n",
    "And\n",
    "\n",
    "$$ \\mathbb{P(Y = 1|X)}$$\n",
    "\n",
    "Note that: \n",
    "\n",
    "$$ \\mathbb{P(Y = 1|X)} = 1 - \\mathbb{P(Y = 0|X)}  $$\n",
    "\n",
    "In other words, the first coordinate is the probability that CT team will lose with the given inputs and the second coordinate is the probability that CT will win with the given inputs. \n",
    "\n",
    "These two probabilities is the final output of the machine learning model. How we use these results is a matter of our fantasy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating the whole serving "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simulate the ML predictions with different inputs visit the interactive Google Colab notebook: https://colab.research.google.com/github/Eligijus112/api-book/blob/main/api-book/chapter-4-ML/machine-learning-model-serving-colab.ipynb. \n",
    "\n",
    "A quick video of the simulation: \n",
    "\n",
    "![colab-walkthrough](media/colab.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations of this approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is perfect to play around with the model and to see how certain feature values influence the model. This interactive notebook could be called as a sufficient serving API for a data scientist for debugging reasons or for presentation of the results.  \n",
    "\n",
    "But we cannot call this type of serving **production** grade serving for several reasons: \n",
    "\n",
    "* The enduser would have to download the notebook, the model and the feature list every time there is an update. \n",
    "* Different machines may produce different results of the notebook (or would produce an error)\n",
    "* It is hard to integrate a jupyter notebook to any working systems that the enduser may have. \n",
    "* The code in the notebook would not deal well with a batch of inputs (>1 row in the dataset)\n",
    "\n",
    "In the next chapters of this book we will explain all the steps and technologies needed in order to create a production ready ML serving system."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "702d029752c7c667e866081f4be82ec9765259a2e8484bced05e549319c2e426"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('api_book': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
