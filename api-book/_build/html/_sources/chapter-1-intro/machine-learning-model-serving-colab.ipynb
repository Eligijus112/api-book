{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating the ML model serving "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to simulate the serving of the ML model with an interactive input. This is a suplementary notebook of the **Machine Learning serving** interactive book by Eligijus Bujokas. The whole project can be viewed via: https://github.com/Eligijus112/api-book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Python packages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the bellow packages are needed to make the interactive simulation possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Json reading \n",
    "import json \n",
    "\n",
    "# Pickle reading \n",
    "import pickle\n",
    "\n",
    "# Operating system functionality \n",
    "import os \n",
    "\n",
    "# Input simulation \n",
    "from ipywidgets import interactive, widgets, interact\n",
    "from IPython.display import display\n",
    "\n",
    "# Data wrangling \n",
    "import pandas as pd\n",
    "\n",
    "# Making requests\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the xgboost version "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make sure that the xboost version in the Google Colab server is on par with the version which was used to create model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the version \n",
    "import xgboost\n",
    "if xgboost.__version__ != \"1.5.0\":\n",
    "    os.system(\"pip install xgboost==1.5.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the necesary objects from Github "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of the files can be accesed in the public GitHub repository: https://github.com/Eligijus112/api-book/tree/main/api-book/ml_models. \n",
    "\n",
    "The **JSON** dictionary can be accesed with a simple GET request. \n",
    "\n",
    "The pickled machine learning model can be downloaded with the **wget** command from the terminal. Because the backend on which Google Colab notebooks are running is Linux with the installed wget functionality, we can access it in the notebooks with the **!** prefix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the features in the master branch \n",
    "url = 'https://raw.githubusercontent.com/Eligijus112/api-book/main/api-book/ml_models/ml-features.json'\n",
    "resp = requests.get(url)\n",
    "features = json.loads(resp.text)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the models\n",
    "!wget https://github.com/Eligijus112/api-book/raw/main/api-book/ml_models/ml-model-lr.pkl\n",
    "!wget https://github.com/Eligijus112/api-book/raw/main/api-book/ml_models/ml-model-xgb.pkl\n",
    "\n",
    "# Reading the pickled model \n",
    "model_lr = pickle.load(open(\"ml-model-lr.pkl\", 'rb'))\n",
    "model_xgb = pickle.load(open(\"ml-model-xgb.pkl\", 'rb'))\n",
    "\n",
    "# Deleting the downloaded file \n",
    "!rm ml-model-lr.pkl \n",
    "!rm ml-model-xgb.pkl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the input preparation function \n",
    "def prepare_input(raw_input_dict: dict, features: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function that accepts the raw input dictionary and the features dictionary and returns a pandas dataframe with the input prepared for the model.\n",
    "    \"\"\"\n",
    "    # Extracting the key names \n",
    "    feature_names = list(raw_input_dict.keys())\n",
    "    original_feature_names = list(features.keys())\n",
    "\n",
    "    # Ensuring that all the keys present in **features** are in **raw_input_dict**\n",
    "    missing_features = set(original_feature_names) - set(feature_names)\n",
    "    if len(missing_features): \n",
    "        return print(f\"Missing features in input: {missing_features}\")\n",
    "\n",
    "    # Iterating and preprocesing \n",
    "    prepared_features = {}\n",
    "    for feature in feature_names:\n",
    "        # Extracting the type of the feature \n",
    "        feature_type = features.get(feature) \n",
    "\n",
    "        # Converting to that type \n",
    "        feature_value = raw_input_dict.get(feature)\n",
    "        \n",
    "        if feature_type == \"float64\":\n",
    "            feature_value = float(feature_value) \n",
    "        \n",
    "        if feature_type == \"int64\":\n",
    "            feature_value = int(feature_value)\n",
    "\n",
    "        # Saving to the prepared features dictionary\n",
    "        prepared_features[feature] = feature_value \n",
    "    \n",
    "    # Creating a dataframe from the prepared features \n",
    "    df = pd.DataFrame(prepared_features, index=[0])\n",
    "\n",
    "    # Ensuring that the names are in the exact order \n",
    "    df = df[original_feature_names]\n",
    "\n",
    "    # Returning the dataframe \n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive serving "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interactive model serving is done using Python and the ipywidgets framework: https://ipywidgets.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the input widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selection widget \n",
    "model_type_widget = widgets.Dropdown(\n",
    "    options=['Logistic Regression', 'Xgboost'],\n",
    "    value='Logistic Regression', \n",
    "    description=\"ML model type\",\n",
    "    disable=False\n",
    ")\n",
    "\n",
    "# Boolean for bomb planting event \n",
    "bomb_planted_widget = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Has the bomb been planted?',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Boolean for the presence of the difusal kit\n",
    "ct_defuse_kit_present_widget = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Is there a difusal kit present in CT team?',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# CT health share of total; the range is (0, 1.0)\n",
    "ct_health_share_widget = widgets.FloatSlider(value=0.5, min=0.0, max=1.0, step=0.05, description='CT health share of total')\n",
    "\n",
    "# Count of CT and T players which are alive\n",
    "ct_players_alive_widget = widgets.Dropdown(\n",
    "    options=list(range(0, 6, 1)),\n",
    "    value=3,\n",
    "    description='The number of alive CT players',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "t_players_alive_widget = widgets.Dropdown(\n",
    "    options=list(range(0, 6, 1)),\n",
    "    value=3,\n",
    "    description='The number of alive T players',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# Number of helmets in a team \n",
    "ct_helmets_widget = widgets.Dropdown(\n",
    "    options=list(range(0, 6, 1)),\n",
    "    value=3,\n",
    "    description='CT helmets',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "t_helmets_widget = widgets.Dropdown(\n",
    "    options=list(range(0, 6, 1)),\n",
    "    value=3,\n",
    "    description='T helmets',\n",
    "    disabled=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob(\n",
    "    model_type,\n",
    "    bomb_planted, \n",
    "    ct_defuse_kit_present,\n",
    "    ct_health_share,\n",
    "    ct_players_alive,\n",
    "    t_players_alive,\n",
    "    ct_helmets, \n",
    "    t_helmets\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Interactive session to experiment with the created ML model \n",
    "    \"\"\"\n",
    "    # Creating the raw input dictionary \n",
    "    raw_input = {\n",
    "        \"bomb_planted\": bomb_planted,\n",
    "        \"ct_defuse_kit_present\": ct_defuse_kit_present,\n",
    "        \"ct_health_share\": ct_health_share, \n",
    "        \"ct_players_alive\": ct_players_alive,\n",
    "        \"t_players_alive\": t_players_alive,\n",
    "        \"ct_helmets\": ct_helmets,\n",
    "        \"t_helmets\": t_helmets\n",
    "    }\n",
    "\n",
    "    # Preparing the input for the model feature importance plot xgboost\n",
    "    raw_input_df = prepare_input(raw_input, features)\n",
    "\n",
    "    # Getting the probabilities \n",
    "    p = [0.5, 0.5]\n",
    "    if model_type == \"Logistic Regression\":\n",
    "        p = model_lr.predict_proba(raw_input_df)[0]\n",
    "    elif model_type == \"Xgboost\":\n",
    "        p = model_xgb.predict_proba(raw_input_df)[0]\n",
    "    \n",
    "    # Extracting the winning probability\n",
    "    p_win = round(p[1], 3)\n",
    "\n",
    "    # Returning the probabilities \n",
    "    print(f\"Probability of CT winning: {p_win}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation application "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the interactive session \n",
    "prob_widget = interactive(\n",
    "    get_prob, \n",
    "    model_type=model_type_widget,\n",
    "    bomb_planted=bomb_planted_widget, \n",
    "    ct_defuse_kit_present=ct_defuse_kit_present_widget,\n",
    "    ct_health_share=ct_health_share_widget,\n",
    "    ct_players_alive=ct_players_alive_widget,\n",
    "    t_players_alive=t_players_alive_widget,\n",
    "    ct_helmets=ct_helmets_widget,\n",
    "    t_helmets=t_helmets_widget,\n",
    ")\n",
    "\n",
    "# Displaying the widget \n",
    "prob_widget"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "702d029752c7c667e866081f4be82ec9765259a2e8484bced05e549319c2e426"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('api_book': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
